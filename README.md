# GPU 요리하기: 하드웨어 전문가의 CUDA 개발자 가이드

**"왜 내 GPU는 비싼 값을 못하고 놀고 있을까요?"**
**"수많은 CUDA 코어를 100% 활용하는 비밀은 무엇일까요?"**

단순히 CUDA API를 사용하는 것을 넘어, GPU라는 거대한 병렬 컴퓨팅 주방이 하드웨어 수준에서 어떻게 동작하는지 깊이 이해하고 싶은 개발자를 위한 강의 시리즈 "GPU 요리하기"의 공식 GitHub 저장소에 오신 것을 환영합니다.

저는 30년 이상 자동제어, 임베디드 시스템, 전자회로 분야에서 일해온 하드웨어 아키텍트입니다. 이 시리즈에서는 저의 경험을 바탕으로, 추상화된 CUDA 코드 너머에 있는 하드웨어의 동작 원리를 파헤치고, 그 지식이 어떻게 코드 최적화로 이어지는지를 생생하게 보여드립니다.

[▶️**유튜브 전체 강의 시리즈 바로가기 (https://bit.ly/GPU-COOK**)]

---

### 📚 시리즈 소개

본 시리즈는 GPU를 하나의 거대한 '주방'에, CUDA 프로그래밍을 '요리'에 비유하여 네 개의 강좌를 통해 점진적으로 심화되는 내용을 다룹니다.

* **1강: GPU 속이 궁금해? - 주방의 모든 것 파헤치기**
    * CPU(지구인 셰프)와 GPU(안드로메다 셰프)의 근본적인 차이점부터 시작합니다.
    * 요리 도구인 SM, CUDA 코어, 워프(Warp)의 정체와 동작 방식을 하드웨어 관점에서 해부합니다.
    * 재료 창고인 메모리 계층 구조(레지스터, 공유 메모리, 캐시, 전역 메모리)가 성능에 미치는 영향을 알아봅니다.

* **2강: 숨은 병목 찾기 - 데이터 전송 시간을 잡아라!**
    * GPU 연산이 아무리 빨라도 소용없는 진짜 이유, 바로 Host(CPU)와 Device(GPU) 간의 '데이터 전송'이라는 숨은 병목을 찾아냅니다.
    * NVIDIA Nsight Systems 프로파일러를 이용해 GPU의 모든 동작을 CCTV처럼 감시하고, 성능 저하의 원인을 시각적으로 분석하는 방법을 배웁니다.

* **3강: 마법의 작업대, 공유 메모리 - 최고의 요리(커널) 만들기**
    * 느린 전역 메모리(중앙 창고) 접근을 획기적으로 줄이는 비장의 무기, `__shared__` 메모리(바로 앞 작업대)의 정체와 활용법을 마스터합니다.
    * '통신 오버헤드 제거'와 '공유 메모리 활용'이라는 2단계 최적화를 통해 커널 실행 속도를 극적으로 향상시키는 과정을 코드로 증명합니다.

* **4강: 시간 관리의 마술 - 주방 전체를 춤추게 하라!**
    * 요리(계산)와 재료 준비(데이터 전송)를 동시에 처리하여 GPU를 잠시도 쉬지 않게 만드는 비동기 프로그래밍과 CUDA 스트림의 개념을 정복합니다.
    * Pinned Memory와 다중 DMA 엔진 등 하드웨어 자원을 최대로 활용하여 전체 시스템의 처리량을 극대화하는 비법을 공개합니다.

---

### 💬 참여 및 질문 방법

이 저장소는 강의 영상을 보완하는 상세한 텍스트 설명과 코드를 제공합니다.

* **상세 설명 읽기**: 각 강의 폴더(`lecture-01`, `lecture-02` 등)에서 강의 슬라이드의 내용을 훨씬 더 상세하게 풀어쓴 문서를 읽어보실 수 있습니다.
* **질문 및 토론**: 강의 내용에 대한 질문, 코드에 대한 의문, 혹은 더 깊이 알고 싶은 주제가 있다면 언제든지 **[Issues](https://github.com/your-username/your-repo/issues)** 탭을 통해 새로운 이슈를 등록해주세요. 제가 시간을 내어 직접 답변해 드리고, 다른 분들과도 지식을 공유하는 공간으로 만들어가겠습니다.

여러분의 CUDA '요리' 실력이 한 단계 성장하는 데 이 자료가 도움이 되기를 바랍니다.