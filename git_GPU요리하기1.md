#### 📄 1강 상세 설명: GPU 속이 궁금해? - 주방의 모든 것 파헤치기

**목표:** GPU라는 하드웨어의 기본 구성 요소(SM, CUDA 코어, 메모리 계층)를 이해하고, 이러한 구조적 특징이 CUDA 프로그래밍의 기본 철학인 병렬 처리와 어떻게 연결되는지 파악합니다.
[▶️ 1강 강의 PDF 자료 다운로드](materials/GPU요리하기1.pdf)
**서론: 두 명의 주방장 이야기**

[![](images/Pasted%20image%2020250926155156.png)]

컴퓨팅 세계에는 두 명의 전설적인 주방장이 있습니다.

- **CPU (지구인 일류 주방장):** 못하는 요리가 없는 만능 셰프입니다. 금융 처리, 운영체제 관리, 게임 로직 제어 등 복잡하고 다양한 요리를 순서대로, 아주 정교하게 처리하는 '순차 처리'의 대가입니다.
    
- **GPU (안드로메다 주방장):** 수천, 수만 개의 동일한 재료를 한 번에 손질해야 하는 특별한 상황에 특화된 셰프입니다. 수많은 팔을 이용해 단순하지만 방대한 양의 작업을 동시에 처리하는 '병렬 처리'의 귀재입니다.
    

CUDA 프로그래밍은 바로 이 '안드로메다 주방장'의 특성을 100% 활용하기 위한 요리법입니다.

**1. 병렬 요리의 재료: 행렬(Matrix)**

[![](images/Pasted%20image%2020250926155505.png)]

GPU가 다루는 대부분의 데이터는 본질적으로 '행렬' 형태를 띱니다. 이미지의 각 픽셀 정보(RGB) , 딥러닝 모델의 가중치, 과학 시뮬레이션의 센서 데이터 등 모든 것이 거대한 숫자들의 배열, 즉 행렬로 표현될 수 있습니다. GPU는 이 거대한 행렬의 각 원소에 대해 동일한 연산을 동시에 적용하는 데 최적화된 구조를 가지고 있습니다.

**2. 기본 요리 도구: 스레드, 워프, 그리고 SM**

GPU의 주방은 어떻게 구성되어 있을까요?

- **스레드 (Thread):** 가장 기본적인 일꾼(요리사의 팔 하나)입니다. 행렬의 원소 하나를 계산하는 등, 최소 단위의 작업을 수행합니다. CUDA에서는 개발자가 수백만 개의 스레드를 생성하여 각자 데이터를 처리하도록 지시할 수 있습니다. 각 스레드 처리기 내부에는 정수/실수 연산을 위한 CUDA 코어 , AI 연산을 위한 Tensor 코어 , 그리고 특수 함수 계산을 위한 SFU(Special Function Unit) 등이 있습니다.
    
- **워프 (Warp):** GPU 하드웨어는 스레드를 낱개로 관리하지 않습니다. 32개의 스레드를 한 묶음으로 '워프(Warp)'라는 단위로 관리합니다. 이는 하드웨어 설계상 고정된 값으로, 동일한 워프에 속한 32개의 스레드는 항상 동일한 명령어를 동시에 실행합니다(SIMT: Single Instruction, Multiple Threads). 이 '32'라는 숫자는 CUDA 프로그래밍에서 매우 중요한 의미를 가집니다.
    
- **SM (Streaming Multiprocessor):** SM은 CUDA 코어, Tensor 코어, 워프 스케줄러, 공유 메모리, 레지스터 파일 등을 모두 갖춘 '하나의 완전한 프로세서 묶음'이자, 주방의 '독립된 요리 스테이션'입니다. 개발자가 작업을 던지면, SM은 내부의 워프 스케줄러를 통해 워프들을 효율적으로 스케줄링하여 작업을 처리합니다. 고급형 GPU일수록 더 많은 SM을 탑재하고 있으며, 이는 동시에 더 많은 작업을 처리할 수 있음을 의미합니다.
    

[![](images/Pasted%20image%2020250926155600.png)]

**3. 작업 지시서: 그리드와 스레드 블록**

개발자는 이 수많은 스레드를 어떻게 관리하고 작업을 지시할까요?

- **스레드 블록 (Thread Block):** 관련된 작업을 수행하는 스레드들의 그룹입니다. 같은 블록에 속한 스레드들은 '공유 메모리'라는 빠른 작업 공간을 공유하며 협업할 수 있습니다. 블록의 크기는 워프(32)의 배수로 설정하는 것이 효율적이며(예: 128, 256, 512) , 문제의 특성과 하드웨어 자원을 고려하여 신중하게 결정해야 합니다. 너무 큰 블록은 스레드당 할당되는 레지스터 부족을 야기할 수 있고 , 너무 작은 블록은 SM의 연산 유닛을 충분히 활용하지 못할 수 있습니다.
    
- **그리드 (Grid):** 처리해야 할 전체 문제를 나타내는 스레드 블록들의 배열입니다. 예를 들어 1024x1024 크기의 이미지를 처리한다면, 전체 작업량에 맞춰 그리드의 크기를 정의하게 됩니다.
    

요약하자면,

**개발자는 전체 문제(그리드)를 정의하고, 이를 협업 가능한 단위(블록)로 나눈 뒤, 각 블록이 수많은 일꾼(스레드)으로 구성되도록 작업을 설계합니다.** 이 작업 지시서가 GPU에 전달되면, GPU의 글로벌 스케줄러는 블록들을 여러 SM에 할당하고, 각 SM은 워프 단위로 스레드를 실행합니다.

[이미지 삽입: GPU요리하기1.pdf - 13페이지 그리드-블록-스레드 작업 과정 요약 그림]

**4. 재료 창고의 비밀: 메모리 계층 구조**

GPU의 연산 속도는 메모리 접근 속도보다 수백, 수천 배 빠릅니다. 따라서 어떤 메모리를 사용하느냐가 CUDA 프로그램의 성능을 결정합니다.

[![](images/Pasted%20image%2020250926155649.png)]

- **레지스터 (Register File):** 스레드 각각이 소유한 '앞치마 주머니'입니다. 가장 빠르지만 용량이 가장 작고, 해당 스레드만 접근할 수 있습니다. 커널 내의 지역 변수들이 주로 저장됩니다.
    
- **공유 메모리 (Shared Memory):** 같은 스레드 블록에 속한 스레드들이 공유하는 '작업대 위 선반'입니다. 레지스터보다 느리지만 전역 메모리보다는 훨씬 빠릅니다. 개발자가
    
    `__shared__` 키워드를 통해 직접 제어할 수 있으며, 전역 메모리의 데이터를 이곳으로 가져와 재사용함으로써 성능을 극적으로 향상시킬 수 있습니다.
    
- **L1/L2 캐시 (Cache):** SM 내부 혹은 여러 SM이 공유하는 똑똑한 임시 저장 공간입니다. 하드웨어가 자동으로 자주 사용하는 데이터를 임시 저장하여 전역 메모리 접근을 줄여줍니다.
    
- **전역 메모리 (Global Memory / HBM):** GPU에 장착된 대용량 DRAM입니다. 용량은 가장 크지만 속도가 가장 느립니다. 모든 스레드가 접근할 수 있으며, Host(CPU)와 데이터를 주고받는 통로가 됩니다.
    
    **CUDA 최적화의 핵심은 바로 이 느린 전역 메모리 접근을 최소화하는 것입니다.**
    

**결론:** 1강에서는 CUDA 프로그래밍의 기초가 되는 GPU 하드웨어의 구조를 살펴보았습니다. SM, 워프, 블록, 그리드의 관계와 고속도로-국도-골목길처럼 계층화된 메모리 구조를 이해하는 것은 앞으로 진행될 성능 최적화의 가장 중요한 첫걸음입니다.