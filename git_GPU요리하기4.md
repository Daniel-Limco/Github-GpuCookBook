#### 📄 4강 상세 설명: 시간 관리의 마술 - 주방 전체를 춤추게 하라!

**목표:** 3강의 최적화를 뛰어넘어, GPU의 모든 하드웨어 자원을 잠시도 쉬지 않고 100% 가동시키는 궁극의 최적화 기법, '비동기 프로그래밍'과 'CUDA 스트림'을 마스터합니다.
[▶️ 4강 강의 PDF 자료 다운로드](materials/GPU요리하기4.pdf)
**서론: 여전히 놀고 있는 자원들**

3강의 최적화를 통해 GPU의 계산 효율은 크게 높아졌습니다. 하지만 Nsight Systems 프로파일을 더 깊이 들여다보면, 여전히 안타까운 장면들이 보입니다.

[![](images/Pasted%20image%2020250926161509.png)]

- 데이터를 전송하는 동안에는 GPU 연산 코어가 놉니다.
    
- 연산을 하는 동안에는 데이터 전송 통로(PCIe 버스)와 CPU가 놉니다.
    
- 결과를 다시 가져오는 동안에도 GPU 연산 코어가 놉니다.
    

이것이 바로 **동기식(Synchronous) 처리**의 한계입니다. 한 가지 작업이 완전히 끝나야만 다음 작업을 시작하는 방식으로는 주방 전체의 효율을 높일 수 없습니다. 최고의 요리사 한 명보다, 주방 전체가 유기적으로 돌아가는 시스템이 진정한 고수입니다.

**1. 해결책: CUDA 스트림과 비동기(Asynchronous) 실행**

해결책은 '요리(계산)'와 '재료 준비(데이터 전송)'를 **동시에** 처리하는 것입니다. 이것을 가능하게 하는 기술이 바로 **CUDA 스트림(Stream)**입니다.

[![](images/Pasted%20image%2020250926161554.png)]

CUDA 스트림을 주방에 비유하면 다음과 같습니다.

- **총주방장 (CPU):** 큰 주문서(전체 데이터)를 처리하기 쉬운 여러 개의 작은 지시서(chunk)로 나눕니다.
    
- **독립된 요리 라인 (CUDA Streams):** 여러 개의 독립적인 명령 큐입니다. 총주방장은 각 요리 라인에 "재료 운반해!", "요리 시작해!", "완성품 가져와!" 같은 지시를 순서대로 내려보냅니다.
    
- **자율주행 배달부 (DMA Engines):** CPU의 간섭 없이 데이터 운반을 전담하는 하드웨어 엔진입니다. CPU가 "배달 시작!"(`cudaMemcpyAsync`)이라는 **논블로킹(Non-blocking)** 명령만 내리면, 배달부가 운반하는 동안 CPU와 요리사(SM)는 각자 다른 일을 동시에 진행할 수 있습니다.
    
- **배달 전용 냉장고 (Pinned Memory):** 배달부(DMA)가 지체 없이 재료를 가져갈 수 있도록 약속된 특별한 메모리 구역입니다. `malloc` 대신 `cudaMallocHost`로 할당하며, OS가 마음대로 주소를 옮기지 않아 DMA가 직접 빠르고 안정적으로 접근할 수 있습니다.
    

[![](images/Pasted%20image%2020250926161635.png)]

이 완벽한 분업과 협력(오버랩, Overlap)을 통해 GPU의 모든 자원을 낭비 없이 사용하여 전체 시스템의 처리량을 극대화할 수 있습니다.

**2. 비동기식 코드 구현 3단계**

비동기식 코드는 동기식 코드보다 조금 더 복잡하지만, 그 구조를 이해하면 명확합니다.

- **1단계: 준비 작업**
    
    - 여러 개의 요리 라인(스트림)을 만듭니다 (`cudaStreamCreate`).
        
    - 일반 메모리(`malloc`) 대신 배달 전용 냉장고(Pinned Memory)를 할당받습니다 (`cudaMallocHost`).
        
    
    [![](images/Pasted%20image%2020250926161733.png)]
    
- **2단계: 작업 분할 및 명령 전달 (루프)**
    
    - 전체 데이터를 스트림 개수만큼 잘게 나눕니다(chunk).
        
    - 반복문을 돌며 각 데이터 조각(chunk)을 각기 다른 스트림에 할당합니다.
        
    - 각 스트림에 **비동기(Async)** 버전의 명령을 순서대로 내립니다.
        
        1. `cudaMemcpyAsync(..., stream[i])`: i번 배달부! i번 재료를 옮겨라!
            
        2. `kernel<<<..., stream[i]>>>`: i번 요리사! 재료 도착하면 요리 시작해!
            
        3. `cudaMemcpyAsync(..., stream[i])`: i번 배달부! 요리 끝나면 결과 가져와!
            
    - CPU는 이 명령들만 내리고 즉시 다음 루프로 넘어갑니다. 실제 작업은 GPU의 하드웨어(DMA, SM)가 알아서 처리합니다.
        
    
    [![](images/Pasted%20image%2020250926161817.png)]
    
- **3단계: 최종 동기화**
    
    - 모든 명령을 내린 후, CPU는 `cudaDeviceSynchronize()`를 호출하여 모든 스트림의 모든 작업이 완료될 때까지 딱 한 번만 기다립니다. "모든 요리 다 끝나고 주방 정리될 때까지 퇴근 금지!"라는 최종 명령과 같습니다.
        
    
    [![](images/Pasted%20image%2020250926161858.png)]
    

**3. 결과: 100% 가동되는 완벽한 파이프라인**

[![](images/Pasted%20image%2020250926161927.png)]

비동기 스트림을 적용한 후의 프로파일은 예술 그 자체입니다.

- **계단식 파이프라인:** 데이터 전송(HtoD), 커널 실행, 결과 전송(DtoH)이 서로 다른 스트림에서 맞물려 돌아가며 빈틈없이 실행됩니다 (완벽한 오버랩).
    
- **CPU의 역할 변화 (Fire-and-Forget):** CPU는 초반에 모든 명령을 GPU에 위임하고 긴 동기화 대기 상태에 들어갑니다. 더 이상 CPU가 병목이 아님을 증명합니다.
    
- **끊김 없는 데이터 흐름:** PCIe 대역폭(빨간색 그래프)이 중간에 끊기지 않고 꾸준히 활용되어 GPU가 굶주리지 않도록 데이터가 계속 공급됩니다.
    
- **GPU 효율 100%:** 파이프라인 덕분에 SM의 활성도(노란색 그래프)가 작업 내내 높은 수준으로 유지됩니다. 비싼 GPU의 연산 자원이 낭비 없이 최대한으로 사용되고 있음을 보여줍니다.
    

**결론:** 4강에서는 동기식 처리의 한계를 극복하고 CUDA 스트림과 Pinned Memory, DMA 엔진이라는 하드웨어 기능을 활용하여 데이터 전송과 연산을 오버랩시키는 비동기 프로그래밍 기법을 배웠습니다. 이는 개별 작업의 속도를 높이는 것을 넘어, 시스템 전체의 처리량(Throughput)을 극대화하는 CUDA 성능 최적화의 정점이라 할 수 있습니다.